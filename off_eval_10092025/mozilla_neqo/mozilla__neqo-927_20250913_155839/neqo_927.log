[2025-09-13 15:58:40] INFO     : Linked issue found
[2025-09-13 15:58:41] INFO     : Repository does not exist yet, cloning...
[2025-09-13 15:58:41] INFO     : Cloning repository https://github.com/mozilla/neqo.git
[2025-09-13 15:58:43] SUCCESS  : Cloning successful
[2025-09-13 15:58:43] MARKER   : Checking Docker image...
[2025-09-13 15:58:43] MARKER   : Image not found. Building image...
[2025-09-13 15:58:43] MARKER   : Using standard Dockerfile for neqo
[2025-09-13 15:59:00] SUCCESS  : Docker image 'image_mozilla__neqo-927:latest' built successfully
[2025-09-13 15:59:00] MARKER   : Attempt 1 with model gpt-4o
[2025-09-13 15:59:00] MARKER   : =============== Test Generation Started ==============
[2025-09-13 15:59:00] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_neqo/mozilla__neqo-927_20250913_155839/i1_gpt-4o/prompt.txt
[2025-09-13 15:59:00] INFO     : Querying LLM...
[2025-09-13 15:59:06] INFO     : HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-13 15:59:06] SUCCESS  : LLM response received
[2025-09-13 15:59:06] MARKER   : File neqo-transport/src/cc.rs exists in commit 1fe8ecfa3084ae44e5877d2ab4fb320c0670f8c6
[2025-09-13 15:59:06] MARKER   : File neqo-transport/src/cc.rs exists in base commit
[2025-09-13 15:59:06] MARKER   : Running test in pre-PR codebase...
[2025-09-13 15:59:06] MARKER   : Creating container...
[2025-09-13 15:59:08] MARKER   : Container 16fc6264f8ac started
[2025-09-13 15:59:08] MARKER   : File /tmp/tmpeoa2yeur added to container successfully
[2025-09-13 15:59:08] MARKER   : [+] Applying patch
[2025-09-13 15:59:08] INFO     : [+] Patch applied successfully.
[2025-09-13 15:59:08] MARKER   : Tests to run: test_persistent_congestion_detection
[2025-09-13 15:59:22] INFO     : [+] Test command executed.
[2025-09-13 15:59:22] INFO     : [+] Test result: False
[2025-09-13 15:59:35] INFO     : [*] Container stopped and removed.
[2025-09-13 15:59:35] INFO     : Getting file content from head commit rather than checking out commit...
[2025-09-13 15:59:35] MARKER   : File neqo-transport/src/cc.rs exists in head commit
[2025-09-13 15:59:35] MARKER   : Running test in post-PR codebase...
[2025-09-13 15:59:35] MARKER   : Creating container...
[2025-09-13 15:59:36] MARKER   : Container b82465494105 started
[2025-09-13 15:59:36] MARKER   : [+] Applying golden code patch
[2025-09-13 15:59:36] MARKER   : File /tmp/tmpc9uklxgv added to container successfully
[2025-09-13 15:59:36] MARKER   : [+] Applying patch
[2025-09-13 15:59:36] INFO     : [+] Patch applied successfully.
[2025-09-13 15:59:36] MARKER   : Tests to run: test_persistent_congestion_detection
[2025-09-13 15:59:52] INFO     : [+] Test command executed.
[2025-09-13 15:59:52] INFO     : [+] Test result: False
[2025-09-13 16:00:04] INFO     : [*] Container stopped and removed.
[2025-09-13 16:00:04] INFO     : No Fail-to-Pass test generated
[2025-09-13 16:00:04] MARKER   : =============== Test Generation Finished =============
[2025-09-13 16:00:04] SUCCESS  : Attempt 1 with model gpt-4o finished successfully
[2025-09-13 16:00:04] INFO     : Environment already prepared, skipping preparation phase...
[2025-09-13 16:00:04] MARKER   : Attempt 1 with model llama-3.3-70b-versatile
[2025-09-13 16:00:04] MARKER   : =============== Test Generation Started ==============
[2025-09-13 16:00:04] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_neqo/mozilla__neqo-927_20250913_155839/i1_llama-3.3-70b-versatile/prompt.txt
[2025-09-13 16:00:04] INFO     : Querying LLM...
[2025-09-13 16:00:05] INFO     : HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-13 16:00:05] SUCCESS  : LLM response received
[2025-09-13 16:00:05] MARKER   : File neqo-transport/src/cc.rs exists in commit 1fe8ecfa3084ae44e5877d2ab4fb320c0670f8c6
[2025-09-13 16:00:05] MARKER   : File neqo-transport/src/cc.rs exists in base commit
[2025-09-13 16:00:05] MARKER   : Running test in pre-PR codebase...
[2025-09-13 16:00:05] MARKER   : Creating container...
[2025-09-13 16:00:07] MARKER   : Container c71af223b227 started
[2025-09-13 16:00:07] MARKER   : File /tmp/tmptvou9dnl added to container successfully
[2025-09-13 16:00:07] MARKER   : [+] Applying patch
[2025-09-13 16:00:07] INFO     : [+] Patch applied successfully.
[2025-09-13 16:00:07] MARKER   : Tests to run: test_persistent_congestion
[2025-09-13 16:00:21] INFO     : [+] Test command executed.
[2025-09-13 16:00:21] INFO     : [+] Test result: False
[2025-09-13 16:00:33] INFO     : [*] Container stopped and removed.
[2025-09-13 16:00:33] INFO     : Getting file content from head commit rather than checking out commit...
[2025-09-13 16:00:33] MARKER   : File neqo-transport/src/cc.rs exists in head commit
[2025-09-13 16:00:33] MARKER   : Running test in post-PR codebase...
[2025-09-13 16:00:33] MARKER   : Creating container...
[2025-09-13 16:00:35] MARKER   : Container 20c700acbdc9 started
[2025-09-13 16:00:35] MARKER   : [+] Applying golden code patch
[2025-09-13 16:00:35] MARKER   : File /tmp/tmpvh67xy58 added to container successfully
[2025-09-13 16:00:35] MARKER   : [+] Applying patch
[2025-09-13 16:00:35] INFO     : [+] Patch applied successfully.
[2025-09-13 16:00:35] MARKER   : Tests to run: test_persistent_congestion
[2025-09-13 16:00:51] INFO     : [+] Test command executed.
[2025-09-13 16:00:51] INFO     : [+] Test result: False
[2025-09-13 16:01:03] INFO     : [*] Container stopped and removed.
[2025-09-13 16:01:03] INFO     : No Fail-to-Pass test generated
[2025-09-13 16:01:03] MARKER   : =============== Test Generation Finished =============
[2025-09-13 16:01:03] SUCCESS  : Attempt 1 with model llama-3.3-70b-versatile finished successfully
[2025-09-13 16:01:03] INFO     : Environment already prepared, skipping preparation phase...
[2025-09-13 16:01:03] MARKER   : Attempt 1 with model deepseek-r1-distill-llama-70b
[2025-09-13 16:01:03] MARKER   : =============== Test Generation Started ==============
[2025-09-13 16:01:03] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_neqo/mozilla__neqo-927_20250913_155839/i1_deepseek-r1-distill-llama-70b/prompt.txt
[2025-09-13 16:01:03] INFO     : Querying LLM...
[2025-09-13 16:01:08] INFO     : HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-13 16:01:08] SUCCESS  : LLM response received
[2025-09-13 16:01:08] INFO     : Model determined no test is needed.
[2025-09-13 16:01:08] MARKER   : =============== Test Generation Finished ==============
[2025-09-13 16:01:08] INFO     : Model did not return a test, skipping...
[2025-09-13 16:01:08] SUCCESS  : Attempt 1 with model deepseek-r1-distill-llama-70b finished successfully
