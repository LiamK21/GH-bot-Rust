[2025-09-13 12:37:02] INFO     : Linked issue found
[2025-09-13 12:37:06] INFO     : Repository does not exist yet, cloning...
[2025-09-13 12:37:06] INFO     : Cloning repository https://github.com/mozilla/neqo.git
[2025-09-13 12:37:08] SUCCESS  : Cloning successful
[2025-09-13 12:37:08] MARKER   : Checking Docker image...
[2025-09-13 12:37:08] MARKER   : Image not found. Building image...
[2025-09-13 12:37:08] MARKER   : Using standard Dockerfile for neqo
[2025-09-13 12:37:31] SUCCESS  : Docker image 'image_mozilla__neqo-444:latest' built successfully
[2025-09-13 12:37:31] MARKER   : Attempt 1 with model gpt-4o
[2025-09-13 12:37:31] MARKER   : =============== Test Generation Started ==============
[2025-09-13 12:37:31] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_neqo/mozilla__neqo-444_20250913_123702/i1_gpt-4o/prompt.txt
[2025-09-13 12:37:31] INFO     : Querying LLM...
[2025-09-13 12:37:41] INFO     : HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-13 12:37:41] SUCCESS  : LLM response received
[2025-09-13 12:37:41] MARKER   : File neqo-http3/src/response_stream.rs does not exist in commit 7c971bd1d25150a0b0e8aed0947a4e68a6191155
[2025-09-13 12:37:41] MARKER   : File neqo-http3/src/response_stream.rs does not exist in base commit
[2025-09-13 12:37:41] MARKER   : File did not exist in pre-PR codebase, cannot run test...
[2025-09-13 12:37:41] INFO     : Getting file content from head commit rather than checking out commit...
[2025-09-13 12:37:41] MARKER   : File neqo-http3/src/response_stream.rs exists in head commit
[2025-09-13 12:37:41] MARKER   : Running test in post-PR codebase...
[2025-09-13 12:37:41] MARKER   : Creating container...
[2025-09-13 12:37:43] MARKER   : Container 196aa4994cd1 started
[2025-09-13 12:37:43] MARKER   : Creating empty file in Docker: neqo-http3/src/response_stream.rs
[2025-09-13 12:37:43] MARKER   : Created empty file in Docker: neqo-http3/src/response_stream.rs
[2025-09-13 12:37:43] MARKER   : [+] Applying golden code patch
[2025-09-13 12:37:43] MARKER   : File /tmp/tmpztft8052 added to container successfully
[2025-09-13 12:37:43] MARKER   : [+] Applying patch
[2025-09-13 12:37:43] INFO     : [+] Patch applied successfully.
[2025-09-13 12:37:43] MARKER   : Tests to run: test_response_stream_read_response_headers
[2025-09-13 12:37:51] INFO     : [+] Test command executed.
[2025-09-13 12:37:51] INFO     : [+] Test result: False
[2025-09-13 12:38:03] INFO     : [*] Container stopped and removed.
[2025-09-13 12:38:03] INFO     : No Fail-to-Pass test generated
[2025-09-13 12:38:03] MARKER   : =============== Test Generation Finished =============
[2025-09-13 12:38:03] SUCCESS  : Attempt 1 with model gpt-4o finished successfully
[2025-09-13 12:38:03] INFO     : Environment already prepared, skipping preparation phase...
[2025-09-13 12:38:03] MARKER   : Attempt 1 with model llama-3.3-70b-versatile
[2025-09-13 12:38:03] MARKER   : =============== Test Generation Started ==============
[2025-09-13 12:38:03] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_neqo/mozilla__neqo-444_20250913_123702/i1_llama-3.3-70b-versatile/prompt.txt
[2025-09-13 12:38:03] INFO     : Querying LLM...
[2025-09-13 12:38:05] INFO     : HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-13 12:38:05] SUCCESS  : LLM response received
[2025-09-13 12:38:05] MARKER   : File neqo-http3/src/connection_client.rs exists in commit 7c971bd1d25150a0b0e8aed0947a4e68a6191155
[2025-09-13 12:38:05] MARKER   : File neqo-http3/src/connection_client.rs exists in base commit
[2025-09-13 12:38:05] MARKER   : Running test in pre-PR codebase...
[2025-09-13 12:38:05] MARKER   : Creating container...
[2025-09-13 12:38:07] MARKER   : Container 09da69f9a331 started
[2025-09-13 12:38:07] MARKER   : File /tmp/tmpzp2vhvxa added to container successfully
[2025-09-13 12:38:07] MARKER   : [+] Applying patch
[2025-09-13 12:38:07] INFO     : [+] Patch applied successfully.
[2025-09-13 12:38:07] MARKER   : Tests to run: test_response_stream_state
[2025-09-13 12:38:15] INFO     : [+] Test command executed.
[2025-09-13 12:38:15] INFO     : [+] Test result: False
[2025-09-13 12:38:26] INFO     : [*] Container stopped and removed.
[2025-09-13 12:38:26] INFO     : Getting file content from head commit rather than checking out commit...
[2025-09-13 12:38:26] MARKER   : File neqo-http3/src/connection_client.rs exists in head commit
[2025-09-13 12:38:26] MARKER   : Running test in post-PR codebase...
[2025-09-13 12:38:26] MARKER   : Creating container...
[2025-09-13 12:38:28] MARKER   : Container fb0b5cd19414 started
[2025-09-13 12:38:28] MARKER   : Creating empty file in Docker: neqo-http3/src/response_stream.rs
[2025-09-13 12:38:28] MARKER   : Created empty file in Docker: neqo-http3/src/response_stream.rs
[2025-09-13 12:38:28] MARKER   : [+] Applying golden code patch
[2025-09-13 12:38:28] MARKER   : File /tmp/tmpkm0cvfpt added to container successfully
[2025-09-13 12:38:28] MARKER   : [+] Applying patch
[2025-09-13 12:38:28] INFO     : [+] Patch applied successfully.
[2025-09-13 12:38:28] MARKER   : Tests to run: test_response_stream_state
[2025-09-13 12:38:36] INFO     : [+] Test command executed.
[2025-09-13 12:38:36] INFO     : [+] Test result: False
[2025-09-13 12:38:47] INFO     : [*] Container stopped and removed.
[2025-09-13 12:38:47] INFO     : No Fail-to-Pass test generated
[2025-09-13 12:38:47] MARKER   : =============== Test Generation Finished =============
[2025-09-13 12:38:47] SUCCESS  : Attempt 1 with model llama-3.3-70b-versatile finished successfully
[2025-09-13 12:38:47] INFO     : Environment already prepared, skipping preparation phase...
[2025-09-13 12:38:47] MARKER   : Attempt 1 with model deepseek-r1-distill-llama-70b
[2025-09-13 12:38:47] MARKER   : =============== Test Generation Started ==============
[2025-09-13 12:38:47] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_neqo/mozilla__neqo-444_20250913_123702/i1_deepseek-r1-distill-llama-70b/prompt.txt
[2025-09-13 12:38:47] INFO     : Querying LLM...
[2025-09-13 12:38:51] INFO     : HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-13 12:38:51] SUCCESS  : LLM response received
[2025-09-13 12:38:51] MARKER   : File neqo-http3/src/connection_client.rs exists in commit 7c971bd1d25150a0b0e8aed0947a4e68a6191155
[2025-09-13 12:38:51] MARKER   : File neqo-http3/src/connection_client.rs exists in base commit
[2025-09-13 12:38:51] MARKER   : Running test in pre-PR codebase...
[2025-09-13 12:38:51] MARKER   : Creating container...
[2025-09-13 12:38:53] MARKER   : Container 0efe1282c818 started
[2025-09-13 12:38:53] MARKER   : File /tmp/tmpori3pha1 added to container successfully
[2025-09-13 12:38:53] MARKER   : [+] Applying patch
[2025-09-13 12:38:53] INFO     : [+] Patch applied successfully.
[2025-09-13 12:38:53] MARKER   : Tests to run: test_read_headers_correctly
[2025-09-13 12:39:01] INFO     : [+] Test command executed.
[2025-09-13 12:39:01] INFO     : [+] Test result: False
[2025-09-13 12:39:12] INFO     : [*] Container stopped and removed.
[2025-09-13 12:39:12] INFO     : Getting file content from head commit rather than checking out commit...
[2025-09-13 12:39:12] MARKER   : File neqo-http3/src/connection_client.rs exists in head commit
[2025-09-13 12:39:12] MARKER   : Running test in post-PR codebase...
[2025-09-13 12:39:12] MARKER   : Creating container...
[2025-09-13 12:39:15] MARKER   : Container c04029197af9 started
[2025-09-13 12:39:15] MARKER   : Creating empty file in Docker: neqo-http3/src/response_stream.rs
[2025-09-13 12:39:15] MARKER   : Created empty file in Docker: neqo-http3/src/response_stream.rs
[2025-09-13 12:39:15] MARKER   : [+] Applying golden code patch
[2025-09-13 12:39:15] MARKER   : File /tmp/tmpaws8u5cf added to container successfully
[2025-09-13 12:39:15] MARKER   : [+] Applying patch
[2025-09-13 12:39:15] INFO     : [+] Patch applied successfully.
[2025-09-13 12:39:15] MARKER   : Tests to run: test_read_headers_correctly
[2025-09-13 12:39:23] INFO     : [+] Test command executed.
[2025-09-13 12:39:23] INFO     : [+] Test result: False
[2025-09-13 12:39:34] INFO     : [*] Container stopped and removed.
[2025-09-13 12:39:34] INFO     : No Fail-to-Pass test generated
[2025-09-13 12:39:34] MARKER   : =============== Test Generation Finished =============
[2025-09-13 12:39:34] SUCCESS  : Attempt 1 with model deepseek-r1-distill-llama-70b finished successfully
