[2025-09-10 12:22:56] INFO     : Linked issue found
[2025-09-10 12:22:58] INFO     : Repository does not exist yet, cloning...
[2025-09-10 12:22:58] INFO     : Cloning repository https://github.com/mozilla/grcov.git
[2025-09-10 12:23:00] SUCCESS  : Cloning successful
[2025-09-10 12:23:00] MARKER   : Checking Docker image...
[2025-09-10 12:23:00] MARKER   : Image not found. Building image...
[2025-09-10 12:23:00] WARNING  : Using old Dockerfile for grcov
[2025-09-10 12:24:40] SUCCESS  : Docker image 'image_mozilla__grcov-255:latest' built successfully
[2025-09-10 12:24:40] MARKER   : Attempt 1 with model gpt-4o
[2025-09-10 12:24:40] MARKER   : =============== Test Generation Started ==============
[2025-09-10 12:24:40] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_grcov/mozilla__grcov-255_20250910_122256/i1_gpt-4o/prompt.txt
[2025-09-10 12:24:40] INFO     : Querying LLM...
[2025-09-10 12:24:45] INFO     : HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-10 12:24:45] SUCCESS  : LLM response received
[2025-09-10 12:24:45] MARKER   : File src/output.rs exists in commit 647a9cb99708bb10a2a035a75830b6b6d56f970c
[2025-09-10 12:24:45] MARKER   : File src/output.rs exists in base commit
[2025-09-10 12:24:45] MARKER   : Running test in pre-PR codebase...
[2025-09-10 12:24:45] MARKER   : Creating container...
[2025-09-10 12:24:46] MARKER   : Container 0dc6818d81f0 started
[2025-09-10 12:24:46] MARKER   : File /tmp/tmp3s089bug added to container successfully
[2025-09-10 12:24:46] MARKER   : [+] Applying patch
[2025-09-10 12:24:46] INFO     : [+] Patch applied successfully.
[2025-09-10 12:24:46] MARKER   : Tests to run: test_output_lcov_to_file
[2025-09-10 12:24:50] INFO     : [+] Test command executed.
[2025-09-10 12:24:50] INFO     : [+] Test result: False
[2025-09-10 12:25:01] INFO     : [*] Container stopped and removed.
[2025-09-10 12:25:01] INFO     : Getting file content from head commit rather than checking out commit...
[2025-09-10 12:25:01] MARKER   : File src/output.rs exists in head commit
[2025-09-10 12:25:01] MARKER   : Running test in post-PR codebase...
[2025-09-10 12:25:01] MARKER   : Creating container...
[2025-09-10 12:25:03] MARKER   : Container 23edb5c974ed started
[2025-09-10 12:25:03] MARKER   : [+] Applying golden code patch
[2025-09-10 12:25:03] MARKER   : File /tmp/tmp4p6neher added to container successfully
[2025-09-10 12:25:03] MARKER   : [+] Applying patch
[2025-09-10 12:25:03] INFO     : [+] Patch applied successfully.
[2025-09-10 12:25:03] MARKER   : Tests to run: test_output_lcov_to_file
[2025-09-10 12:25:08] INFO     : [+] Test command executed.
[2025-09-10 12:25:08] INFO     : [+] Test result: False
[2025-09-10 12:25:19] INFO     : [*] Container stopped and removed.
[2025-09-10 12:25:19] INFO     : No Fail-to-Pass test generated
[2025-09-10 12:25:19] MARKER   : =============== Test Generation Finished =============
[2025-09-10 12:25:19] SUCCESS  : Attempt 1 with model gpt-4o finished successfully
[2025-09-10 12:25:19] INFO     : Environment already prepared, skipping preparation phase...
[2025-09-10 12:25:19] MARKER   : Attempt 1 with model llama-3.3-70b-versatile
[2025-09-10 12:25:19] MARKER   : =============== Test Generation Started ==============
[2025-09-10 12:25:19] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_grcov/mozilla__grcov-255_20250910_122256/i1_llama-3.3-70b-versatile/prompt.txt
[2025-09-10 12:25:19] INFO     : Querying LLM...
[2025-09-10 12:25:20] INFO     : HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-10 12:25:20] SUCCESS  : LLM response received
[2025-09-10 12:25:20] MARKER   : File src/output.rs exists in commit 647a9cb99708bb10a2a035a75830b6b6d56f970c
[2025-09-10 12:25:20] MARKER   : File src/output.rs exists in base commit
[2025-09-10 12:25:20] MARKER   : Running test in pre-PR codebase...
[2025-09-10 12:25:20] MARKER   : Creating container...
[2025-09-10 12:25:22] MARKER   : Container 04fcfe926827 started
[2025-09-10 12:25:22] MARKER   : File /tmp/tmplhaq32c5 added to container successfully
[2025-09-10 12:25:22] MARKER   : [+] Applying patch
[2025-09-10 12:25:22] INFO     : [+] Patch applied successfully.
[2025-09-10 12:25:22] MARKER   : Tests to run: test_output_activedata_etl_with_file
[2025-09-10 12:25:27] INFO     : [+] Test command executed.
[2025-09-10 12:25:27] INFO     : [+] Test result: False
[2025-09-10 12:25:38] INFO     : [*] Container stopped and removed.
[2025-09-10 12:25:38] INFO     : Getting file content from head commit rather than checking out commit...
[2025-09-10 12:25:38] MARKER   : File src/output.rs exists in head commit
[2025-09-10 12:25:38] MARKER   : Running test in post-PR codebase...
[2025-09-10 12:25:38] MARKER   : Creating container...
[2025-09-10 12:25:41] MARKER   : Container 3618714e88d6 started
[2025-09-10 12:25:41] MARKER   : [+] Applying golden code patch
[2025-09-10 12:25:41] MARKER   : File /tmp/tmpa1szkaa2 added to container successfully
[2025-09-10 12:25:41] MARKER   : [+] Applying patch
[2025-09-10 12:25:41] INFO     : [+] Patch applied successfully.
[2025-09-10 12:25:41] MARKER   : Tests to run: test_output_activedata_etl_with_file
[2025-09-10 12:25:46] INFO     : [+] Test command executed.
[2025-09-10 12:25:46] INFO     : [+] Test result: False
[2025-09-10 12:25:58] INFO     : [*] Container stopped and removed.
[2025-09-10 12:25:58] INFO     : No Fail-to-Pass test generated
[2025-09-10 12:25:58] MARKER   : =============== Test Generation Finished =============
[2025-09-10 12:25:58] SUCCESS  : Attempt 1 with model llama-3.3-70b-versatile finished successfully
[2025-09-10 12:25:58] INFO     : Environment already prepared, skipping preparation phase...
[2025-09-10 12:25:58] MARKER   : Attempt 1 with model deepseek-r1-distill-llama-70b
[2025-09-10 12:25:58] MARKER   : =============== Test Generation Started ==============
[2025-09-10 12:25:58] MARKER   : New prompt written to /home/ubuntu/GH-bot-Rust/bot_logs/mozilla_grcov/mozilla__grcov-255_20250910_122256/i1_deepseek-r1-distill-llama-70b/prompt.txt
[2025-09-10 12:25:58] INFO     : Querying LLM...
[2025-09-10 12:26:00] INFO     : HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-10 12:26:00] SUCCESS  : LLM response received
[2025-09-10 12:26:00] CRITICAL : Another error occurred during runner execution: Filename received from model does not exist
