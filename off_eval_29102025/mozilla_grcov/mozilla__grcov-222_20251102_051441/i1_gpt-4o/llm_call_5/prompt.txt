Before you begin:
- Keep going until the job is completely solved — don’t stop halfway.
- If you’re unsure about the behavior, reread the provided patch carefully; do not hallucinate.
- Plan your approach before writing code by reflecting on whether the test truly fails before and passes after.

Issue:
<issue>
If a thread fails, the error code should not be 0
```
marco@marco ~/Documenti $ grcov jsvm/file.info 
thread '<unnamed>' panicked at 'No input files found', src/producer.rs:425:5
note: Run with `RUST_BACKTRACE=1` for a backtrace.
marco@marco ~/Documenti $ echo $?
0
```
</issue>

Patch:
<patch>
diff --git a/src/main.rs b/src/main.rs
--- a/src/main.rs
+++ b/src/main.rs
@@ -297,7 +297,9 @@ fn main() {
         parsers.push(t);
     }
 
-    let _ = producer.join();
+    if let Err(_) = producer.join() {
+        process::exit(1);
+    }
 
     // Poison the queue, now that the producer is finished.
     for _ in 0..num_threads {
@@ -305,7 +307,9 @@ fn main() {
     }
 
     for parser in parsers {
-        parser.join().unwrap();
+        if let Err(_) = parser.join() {
+            process::exit(1);
+        }
     }
 
     let result_map_mutex = Arc::try_unwrap(result_map).unwrap();


</patch>

<TEST>
<Filename>src/main.rs</Filename>
<imports>use std::process::Command;
use std::str;</imports>
<Rust>#[test]
fn test_thread_failure_exit_code() {
    let output = Command::new("cargo")
        .arg("run")
        .arg("--")
        .arg("non_existent_file")
        .output()
        .expect("Failed to execute command");

    let stderr = str::from_utf8(&output.stderr).expect("Failed to read stderr");
    let exit_code = output.status.code().unwrap_or(-1);

    assert!(stderr.contains("No input files found"), "Expected error message not found in stderr");
    assert_ne!(exit_code, 0, "Expected non-zero exit code on thread failure");
}
</Rust>
</TEST>

<output>
running 0 tests

test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 69 filtered out; finished in 0.00s

running 1 test
thread 'tests::test_thread_failure_exit_code' panicked at 'Expected error message not found in stderr', src/main.rs:379:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
test tests::test_thread_failure_exit_code ... FAILED
</output>

Function signatures
<Signatures>
fn main() -> ()
</Signatures>

You are a software tester at grcov and your are reviewing the above <patch> for the above <issue>.
A unit test has already been created for this PR and can be found alongside the filename and the imports used inside the <TEST> block.The test should fail on the code before the patch, and pass after, hence the test verifies that the patch resolves the issue.
However, the test currently fails after the patch.
Your task is to:
1. Identify and understand why the unit test failed.
2. Update the unit test in the <TEST> block in order for it to fail on the code before the patch, and pass after, hence verifying that the patch resolves the issue.
3. All 'use' declarations must be inside a <imports>...</imports> block. Additionally:
   - Do not use group imports.
  - Import only what is necessary for the test to run and make sure not to have colliding imports.
  - If the <patch> contains a 'mod tests' block with useful imports, do not add them to the <imports> block.
  - Use `use super::<function name> for the function under test.
.  - If multiple 'use' statements are needed, list each on a separate line.
4. To help you write the test, <Signatures> contains all modified function's:
  - name
  - parameters
  - Return type (assume '()' if empty)
5. Return only the absolute filename as it is in the <patch> block, the use statements, and rust test (no comments or explanations).

Follow this expected output format, do not deviate from this structure:
<Filename> ... </Filename>
<imports> ... </imports>
<Rust>
#[test]
fn test_<describe_behavior>() {
  <initialize required variables>;
  <define expected variable>;
  <generate actual variables>;
  <compare expected with actual>;
}</Rust>

